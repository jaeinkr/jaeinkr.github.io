<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

<!-- Begin Jekyll SEO tag v2.7.1 -->
<title>[Paper Note] SimplE Embedding for Link Prediction in Knowledge Graphs (2018) | Jaein Land</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="[Paper Note] SimplE Embedding for Link Prediction in Knowledge Graphs (2018)" />
<meta name="author" content="Jaein Kim" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="11 February 2021 [Paper Note] SimplE Embedding for Link Prediction in Knowledge Graphs (2018) Authors: Seyed Mehran Kazemi, David Poole Keywords: NLP, Link Prediction, Embedding" />
<meta property="og:description" content="11 February 2021 [Paper Note] SimplE Embedding for Link Prediction in Knowledge Graphs (2018) Authors: Seyed Mehran Kazemi, David Poole Keywords: NLP, Link Prediction, Embedding" />
<link rel="canonical" href="http://localhost:4000/paper%20notes/2021/02/11/paper_review.html" />
<meta property="og:url" content="http://localhost:4000/paper%20notes/2021/02/11/paper_review.html" />
<meta property="og:site_name" content="Jaein Land" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-02-11T00:00:00+09:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="[Paper Note] SimplE Embedding for Link Prediction in Knowledge Graphs (2018)" />
<script type="application/ld+json">
{"url":"http://localhost:4000/paper%20notes/2021/02/11/paper_review.html","headline":"[Paper Note] SimplE Embedding for Link Prediction in Knowledge Graphs (2018)","dateModified":"2021-02-11T00:00:00+09:00","datePublished":"2021-02-11T00:00:00+09:00","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/paper%20notes/2021/02/11/paper_review.html"},"author":{"@type":"Person","name":"Jaein Kim"},"description":"11 February 2021 [Paper Note] SimplE Embedding for Link Prediction in Knowledge Graphs (2018) Authors: Seyed Mehran Kazemi, David Poole Keywords: NLP, Link Prediction, Embedding","@type":"BlogPosting","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv.min.js"></script>
    <![endif]-->
  </head>




  <body>
    <div class="wrapper">
      <header>
        <h1><a href="http://localhost:4000/">Jaein Land</a></h1>
        
        

        <p>NLP and others</p>

        

        

        
      </header>
      <section>

      <p>11 February 2021 </p>
<h2 id="paper-note-simple-embedding-for-link-prediction-in-knowledge-graphs-2018">[Paper Note] <a href="https://arxiv.org/pdf/1802.04868.pdf">SimplE Embedding for Link Prediction in Knowledge Graphs</a> (2018)</h2>
<h4 id="authors-seyed-mehran-kazemi-david-poole">Authors: Seyed Mehran Kazemi, David Poole</h4>
<blockquote>
  <p>Keywords: NLP, Link Prediction, Embedding</p>
</blockquote>

<p><br /></p>
<h3 id="task-statements">Task Statements</h3>
<p><strong>Link Prediction</strong> is a task of Knowledge Graph (KG), and its definition is as follows. 
KG is composed of many triples, where each triple is represented by <em>(head, relation, tail)</em>, and the goal of Link Prediction is to predict new triples using given triples to make a complete KG. <br />
This paper proposed an embedding model <strong>SimplE</strong> based on the Canonical Polyadic (CP) decomposition method which is one of tensor factorization methods. 
According to the authors, while SimplE overperforms many existing SOTA models based on tensor factorization approach, it is ‘simpler’, interpretable and expressive.</p>

<h3 id="motivation">Motivation</h3>
<p><em>Canonical Polyadic (CP) decomposition is among the first tensor factorization approaches. CP generally performs poorly for link prediction as it learns two independent embedding vectors for each entity, whereas they are really tied.</em></p>

<h3 id="contributions">Contributions</h3>
<ul>
  <li>Presented a simple enhancement model of CP, <strong>SimplE</strong>, to allow the two embeddings of related each entity to be learned dependently.</li>
  <li>interpretable, fully expressive</li>
  <li>certain types of background knowledge can be incorporated into these embeddings through weight tying</li>
</ul>

<h3 id="overview">Overview</h3>

<h3 id="method">Method</h3>

<p>Whereas the previous embedding models of Link Prediction tended to learn by equating head embedding and tail embedding, SimplE separates the head and tail and trains them independently. In the process, embedding is learned more efficiently by using Symmetry, anti-symmetry, and inversion.
Tensor decomposition is a concept that is widely used in recommendation and prediction models. It works by decomposing a sparse matrix and filling the original matrix for prediction. CP decomposition is also one of these decomposition methods.
 The reason why we can improve the computation speed by two to four times over the contrasting model ComplEx is that it removes redundant elements in various ways, including the techniques mentioned above.</p>

<h3 id="conclusions">Conclusions</h3>
<p>The experimental results shows the performance of SimplE is comparable to or superior to the existing models, while faster and more efficient learning is possible.<br />
Nowadays, language models such as GPT-2 and GPT-3, which are trained with billion-parameter or even trillion-parameter that requires enormous computation resources, are in the spotlight in NLP research. 
However, that also led many AI research to focus on conducting lightweight and efficient models capable of fast learning with a small amount of resources.</p>


      </section>
      <footer>
        
        <p><small>Welcome to Jaein Land!</small></p>
      </footer>
    </div>
    <script src="/assets/js/scale.fix.js"></script>
    
  </body>
</html>
